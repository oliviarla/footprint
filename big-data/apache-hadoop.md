# Apache Hadoop

* 대용량의 비정형 데이터를 처리하기 위해 고안된 기술로, 적당한 성능의 컴퓨터 여러대를 클러스터화하여 데이터를 병렬로 처리한다.

### HDFS

* Java로 작성된 분산 확장 파일 시스템(Hadoop Distributed File System)
* 기존의 파일 시스템 상위에서 동작하며, 여러 장비에 대용량 파일들을 나누어 저장해 안정성을 얻는다.
* Disk I/O에 의해 성능 저하를 유발하여 In-Memory 방식인 Apache Spark가 이를 개선하기 위해 등장했다.

#### 저장 방식

* 큰 데이터를 block 단위로 나누어 저장한다.
* block은 다른 서버에도 복제하여 장애가 발생하더라도 원활히 데이터에 접근할 수 있도록 한다.
* 한 번 저장한 데이터는 수정이 불가능하다.
* 데이터 지역성을 통해 MapReduce가 처리 속도를 증가시킬 수 있다.

#### 구성

* 기본적으로 master-slave 구조이다.
* HDFS는 마스터 역할을 하는 네임 노드 한 개와 슬레이브 역할을 하는 데이터 노드 여러 개로 구성된다.
* 네임 노드는 메타데이터를 가지고 있어 사용자로부터 요청이 왔을 때 데이터 노드를 이용해 응답을 보내준다.
* 데이터 노드에는 파일이 block 단위로 저장되며 주기적으로 네임 노드에 heartbeat와 block report를 전달한다.

### MapReduce

* 대용량 데이터를 처리하기 위한 분산 프로그래밍 모델
* 다음 네가지 과정을 거쳐 데이터를 처리한다.
* Split
  * 크기가 큰 데이터를 작은 단위로 나누어 HDFS에 분산 저장한다.
* Map
  * 흩어져있는 데이터를 `key-value` 형태로 만든다.
* Shuffling
  * `key-value` 쌍을 key를 기준으로 정렬하고 같은 키를 가진 value들은 `key-value목록` 쌍으로 업데이트한다.
* Reduce
  * 각 `key-value목록` 쌍마다 중복된 key값을 지니는 데이터를 제거하여 합친다.

<figure><img src="../.gitbook/assets/image (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1) (1).png" alt=""><figcaption></figcaption></figure>
