# Kafka Connect

### 개념

* 반복적인 파이프라인 생성 작업이 필요할 때 프로듀서, 컨슈머 애플리케이션을 개발하고 배포하고 운영하는 것은 비효율적이다. 커넥트를 이용하면 특정 작업 형태를 템플릿으로 만들어 둔 커넥터를 실행하여 반복 작업을 줄일 수 있다.
* 파일의 데이터를 토픽으로 보내는 커넥터는 파일이 존재하는 디렉토리 위치, 파일 이름 등 고유한 설정값을 입력받은 후 실행할 수 있을 것이다.
* 소스 커넥터는 프로듀서 역할을 하며, 싱크 커넥터는 컨슈머 역할을 한다.
* MySQL, S3, MongoDB 등과 같은 저장소가 싱크/소스 애플리케이션에 해당한다.
* 커넥트에 커넥터 생성을 요청하면 내부적으로 커넥터와 태스크가 생성된다. 태스크는 커넥터에 종속되어 실질적인 데이터를 처리한다.
* 커넥터를 사용한 파이프라인에 컨버터, 트랜스폼 기능을 추가할 수 있다.
  * 컨버터는 데이터 처리 전 스키마를 변경하도록 도와준다. 예를 들어 JsonConverter, ByteArrayConverter 등이 제공된다.
  * 트랜스폼은 데이터 처리 시 메시지 단위로 데이터를 간단히 변환하려는 용도로 사용된다. 예를 들어 JSON 데이터에서 일부 키 값을 제거/추가할 수 있다.

### 실행 모드

#### 단일 모드 커넥트

* 커넥터 정의하는 파일을 작성하고 해당 파일을 참조하는 단일 커넥트를 실행하여 파이프라인을 생성할 수 있다.
* 단일 애플리케이션으로 실행되므로 SPOF(Single Point of Failure) 지점이 될 수 있어 고가용성 구성이 불가능하다.
* 주로 개발환경이나 중요도가 낮은 파이프라인 운영 시 사용한다.
* connect-standalone.properties 파일에 속성을 설정하여 실행시킬 수 있다.
  * key.converter / value.converter : 데이터를 카프카에 저장하거나 카프카에서 가져올 때 사용하는 컨버터 지정
  * key.converter.schemas.enable / value.converter.schemas.enable : 스키마 형태를 사용하는지 여부
  * offset.storage.file.filename : 오프셋을 저장할 로컬 파일의 경로와 이름 지정
  * offset.flush.intervals.ms : 태스크가 처리 완료한 오프셋을 커밋하는 주기 지정
  * plugin.path : 플러그인 형태로 추가할 커넥터의 디렉토리 주소 지정
*

#### 분산 모드 커넥트

* 두 대 이상의 서버에서 클러스터 형태로 실행되어 단일 모드보다 안전하게 운영할 수 있다.
* 데이터 처리량 변화가 있다면 스케일 아웃할 수 있다.
*







